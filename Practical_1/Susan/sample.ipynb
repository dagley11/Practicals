{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import cross_validation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(predictions,labels):\n",
    "    sum = 0\n",
    "    for i in range(len(labels)):\n",
    "        sum += (predictions[i]-labels[i])**2\n",
    "    return (sum/len(labels))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_LR_predictor(train_data, train_labels, test_data, test_labels, exclist = []):\n",
    "    min_RMSE = None\n",
    "    best_predictor = None\n",
    "    feature_num = train_data.shape[1]\n",
    "    train_existing_predictors = train_data[:, exclist]\n",
    "    train_existing_predictors = pd.DataFrame(train_existing_predictors)\n",
    "    test_existing_predictors= test_data[:, exclist]\n",
    "    test_existing_predictors = pd.DataFrame(test_existing_predictors)\n",
    "    for i in range(feature_num) :\n",
    "        if i not in exclist:\n",
    "            feature_i = train_data[:,np.newaxis, i]\n",
    "            feature_i = pd.DataFrame(feature_i)\n",
    "            predictors = pd.concat((train_existing_predictors, feature_i), axis = 1)\n",
    "            LR1 = LinearRegression()            \n",
    "            LR1.fit(predictors, train_labels)\n",
    "            test_i = test_data[:, np.newaxis, i]\n",
    "            test_i = pd.DataFrame(test_i)\n",
    "            test_predictors = pd.concat((test_existing_predictors, test_i), axis = 1)\n",
    "            test_predict = LR1.predict(test_predictors)\n",
    "            RMSE_score = RMSE(test_predict, test_labels)\n",
    "            if ((min_RMSE == None) or (RMSE_score < min_RMSE)):\n",
    "                min_RMSE = RMSE_score\n",
    "                best_predictor = i\n",
    "    return best_predictor, min_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_predictor(train_data, train_labels, test_data, test_labels, model, exclist = []):\n",
    "    min_RMSE = None\n",
    "    best_predictor = None\n",
    "    feature_num = train_data.shape[1]\n",
    "    train_existing_predictors = train_data[:, exclist]\n",
    "    train_existing_predictors = pd.DataFrame(train_existing_predictors)\n",
    "    test_existing_predictors= test_data[:, exclist]\n",
    "    test_existing_predictors = pd.DataFrame(test_existing_predictors)\n",
    "    for i in range(feature_num) :\n",
    "        if i not in exclist:\n",
    "            feature_i = train_data[:,np.newaxis, i]\n",
    "            feature_i = pd.DataFrame(feature_i)\n",
    "            predictors = pd.concat((train_existing_predictors, feature_i), axis = 1)\n",
    "            Model = model()            \n",
    "            Model.fit(predictors, train_labels)\n",
    "            test_i = test_data[:, np.newaxis, i]\n",
    "            test_i = pd.DataFrame(test_i)\n",
    "            test_predictors = pd.concat((test_existing_predictors, test_i), axis = 1)\n",
    "            test_predict = Model.predict(test_predictors)\n",
    "            RMSE_score = RMSE(test_predict, test_labels)\n",
    "            if ((min_RMSE == None) or (RMSE_score < min_RMSE)):\n",
    "                min_RMSE = RMSE_score\n",
    "                best_predictor = i\n",
    "    return best_predictor, min_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_predictor(train_data, train_labels, test_data, test_labels, model):\n",
    "    last_RMSE = None\n",
    "    mylist = []\n",
    "    existing_predictors = []\n",
    "    while(True):\n",
    "        new_predictor, cur_RMSE = best_predictor(train_data, train_labels, test_data, test_labels, model, mylist)\n",
    "        if ((last_RMSE == None) or (cur_RMSE<last_RMSE)):\n",
    "            mylist.append(new_predictor)\n",
    "            last_RMSE = cur_RMSE\n",
    "        else:\n",
    "            break\n",
    "    return mylist, last_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train1 = pd.read_csv(\"newfeature\\SimilarityV1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train2 = pd.read_csv(\"newfeature\\Bag1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train3 = pd.read_csv(\"newfeature\\Bag2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train4 = pd.read_csv(\"newfeature\\Bag3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train5 = pd.read_csv(\"newfeature\\Bag4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train6 = pd.read_csv(\"newfeature\\Bag5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles  feat_001  feat_002  \\\n",
      "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
      "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
      "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
      "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
      "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
      "\n",
      "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  ...   \\\n",
      "0         0         0         1         0         1         0         0  ...    \n",
      "1         0         0         1         0         1         0         0  ...    \n",
      "2         0         0         1         1         1         0         0  ...    \n",
      "3         0         0         1         1         1         0         0  ...    \n",
      "4         0         0         1         0         1         0         0  ...    \n",
      "\n",
      "   feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
      "0         1         0         0         0         0         0         0   \n",
      "1         1         0         0         1         0         0         0   \n",
      "2         1         0         0         0         1         0         0   \n",
      "3         1         0         0         0         1         0         0   \n",
      "4         1         0         0         0         0         0         0   \n",
      "\n",
      "   feat_255  feat_256   gap  \n",
      "0         0         0  1.19  \n",
      "1         0         0  1.60  \n",
      "2         0         0  1.49  \n",
      "3         0         0  1.36  \n",
      "4         0         0  1.98  \n",
      "\n",
      "[5 rows x 258 columns]\n"
     ]
    }
   ],
   "source": [
    "print df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                             smiles      sim1  \\\n",
      "0           0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...  0.485384   \n",
      "1           1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...  0.441337   \n",
      "2           2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...  0.514501   \n",
      "3           3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...  0.480871   \n",
      "4           4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1  0.437585   \n",
      "\n",
      "       sim2      sim3      sim4      sim5      sim6      sim7      sim8  \\\n",
      "0  0.556582  0.466346  0.536730  0.605935  0.596811  0.494630  0.441875   \n",
      "1  0.514697  0.437576  0.538368  0.482856  0.526786  0.430164  0.394619   \n",
      "2  0.574959  0.471549  0.560948  0.621408  0.613008  0.493862  0.425959   \n",
      "3  0.548297  0.465929  0.573954  0.537569  0.588203  0.480505  0.428044   \n",
      "4  0.460356  0.432432  0.562887  0.422779  0.448397  0.412411  0.453927   \n",
      "\n",
      "     ...        sim24     sim25     sim26     sim27     sim28     sim29  \\\n",
      "0    ...     0.415848  0.514568  0.407338  0.471677  0.324735  0.410533   \n",
      "1    ...     0.396380  0.532801  0.341687  0.541616  0.274704  0.414710   \n",
      "2    ...     0.467417  0.556915  0.396216  0.552471  0.309452  0.427201   \n",
      "3    ...     0.406139  0.539967  0.374046  0.560370  0.301627  0.420070   \n",
      "4    ...     0.383275  0.429830  0.319973  0.394673  0.331487  0.351692   \n",
      "\n",
      "      sim30     sim31     sim32     sim33  \n",
      "0  0.408273  0.527885  0.497788  0.358513  \n",
      "1  0.400246  0.503621  0.495751  0.396442  \n",
      "2  0.442220  0.562467  0.546724  0.380521  \n",
      "3  0.410465  0.573009  0.516059  0.370175  \n",
      "4  0.346384  0.439412  0.406360  0.305164  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print df_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df_train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-da65968f8a01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_train1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_train2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "print df_train4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df_train5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_train6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#store gap values\n",
    "Y_train = df_train.gap.values\n",
    "#row where testing examples start\n",
    "test_idx = df_train.shape[0]\n",
    "#delete 'Id' column\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "#delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print test_idx\n",
    "write_to_file(\"Y_train.csv\", Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DataFrame with all train and test examples so we can more easily apply feature engineering on\n",
    "df_all = pd.concat((df_train, df_test), axis=0)\n",
    "df_all = df_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['smiles'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with new features\n",
    "df_all1 = df_train1.drop(['smiles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_all, df_all1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all2  = df_train2.drop(['smiles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_all, df_all2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all3  = df_train3.drop(['smiles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_all, df_all3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all4 = df_train4.drop(['smiles'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_all, df_all4), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all5 = df_train5.drop(['smiles'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_all, df_all5), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1824230, 330)\n",
      "   index  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
      "0      0         0         0         0         0         1         0   \n",
      "1      1         1         0         0         0         1         0   \n",
      "2      2         1         0         0         0         1         1   \n",
      "3      3         1         0         0         0         1         1   \n",
      "4      4         0         0         0         0         1         0   \n",
      "\n",
      "   feat_007  feat_008  feat_009   ...    NumAliphaticCarbocycles  \\\n",
      "0         1         0         0   ...                          0   \n",
      "1         1         0         0   ...                          1   \n",
      "2         1         0         0   ...                          1   \n",
      "3         1         0         0   ...                          1   \n",
      "4         1         0         0   ...                          0   \n",
      "\n",
      "   NumAliphaticHeterocycles  NumAliphaticRings  NumAmideBonds  \\\n",
      "0                         0                  0              0   \n",
      "1                         2                  3              0   \n",
      "2                         1                  2              0   \n",
      "3                         2                  3              0   \n",
      "4                         0                  0              0   \n",
      "\n",
      "   NumAromaticCarbocycle  NumAromaticHeterocycles  NumAromaticRings  \\\n",
      "0                      0                        6                 6   \n",
      "1                      1                        2                 3   \n",
      "2                      2                        3                 5   \n",
      "3                      2                        2                 4   \n",
      "4                      2                        5                 7   \n",
      "\n",
      "   NumBridgeheadAtoms  NumHBA  NumHBD  \n",
      "0                   0       7       0  \n",
      "1                   0       2       0  \n",
      "2                   0       4       1  \n",
      "3                   0       1       1  \n",
      "4                   0       9       0  \n",
      "\n",
      "[5 rows x 330 columns]\n"
     ]
    }
   ],
   "source": [
    "print df_all.shape\n",
    "print df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write to file\n",
    "#df_all.to_csv(\"df_all.csv\")\n",
    "#df_all =pd.read_csv(df_all.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_all.iloc[:test_idx]\n",
    "X_test = df_all.iloc[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_mytrain, X_mytest, Y_mytrain, Y_mytest = cross_validation.train_test_split(X_train, Y_train, test_size=0.1, random_state=1)\n",
    "#cross_validation. 60% of training data are used as \"mytrain\", 40% of test data\n",
    "#are used as \"mytest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17965293353162534"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_mytrain, Y_mytrain)\n",
    "LR_pred = LR.predict(X_mytest)\n",
    "RMSE(LR_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12157428367051742"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_mytrain, Y_mytrain)\n",
    "RF_pred = RF.predict(X_mytest)\n",
    "RMSE(RF_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"RF_predict.csv\", RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17963218561737324"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2 = Ridge(alpha=2.0)\n",
    "L2.fit(X_mytrain, Y_mytrain) \n",
    "L2_pred = L2.predict(X_mytest)\n",
    "RMSE(L2_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 330)\n"
     ]
    }
   ],
   "source": [
    "print X_mytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-93f78b2fe5b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0meigen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[1;31m#(n_components, n_var)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dalang\\Anaconda2\\lib\\site-packages\\sklearn\\decomposition\\pca.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dalang\\Anaconda2\\lib\\site-packages\\sklearn\\decomposition\\pca.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_float_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;31m# Center data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dalang\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mas_float_array\u001b[1;34m(X, copy, force_all_finite)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# is numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F_CONTIGUOUS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "pca = PCA().fit(X_train)\n",
    "eigen = pca.components_ #(n_components, n_var)\n",
    "X_train_pca = pca.transform(X_mytrain)\n",
    "X_test_pca = pca.transform(X_mytest)\n",
    "PCA_pred = RF.predict(X_test_pca)\n",
    "RMSE(PCA_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print type(df_all), type(df_train1)\n",
    "print df_all.shape, df_train1.shape\n",
    "print df_all.index.values, df_train1.index.values\n",
    "\n",
    "df_all1 = pd.concat([df_all, df_train1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example Feature Engineering\n",
    "\n",
    "this calculates the length of each smile string and adds a feature column with those lengths\n",
    "Note: this is NOT a good feature and will result in a lower score!\n",
    "\"\"\"\n",
    "#smiles_len = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "#df_all['smiles_len'] = pd.DataFrame(smiles_len)\n",
    "\n",
    "\n",
    "#Drop the 'smiles' column\n",
    "df_all = df_all.drop(['smiles'], axis=1)\n",
    "vals = df_all.values\n",
    "X_train = vals[:test_idx]\n",
    "X_test = vals[test_idx:]\n",
    "print (\"Train features:\", X_train.shape)\n",
    "print (\"Train gap:\", Y_train.shape)\n",
    "print (\"Test features:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mytrain, X_mytest, Y_mytrain, Y_mytest = cross_validation.train_test_split(X_train, Y_train, test_size=0.4, random_state=0)\n",
    "#cross_validation. 60% of training data are used as \"mytrain\", 40% of test data\n",
    "#are used as \"mytest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_mytrain, Y_mytrain)\n",
    "LR_pred = LR.predict(X_mytest)\n",
    "\n",
    "RMSE(LR_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_mytrain, Y_mytrain)\n",
    "RF_pred = RF.predict(X_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RMSE(RF_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L2 = Ridge(alpha=1.0)\n",
    "L2.fit(X_train, Y_train) \n",
    "L2_pred = L2.predict(X_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RMSE(L2_pred, Y_mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print select_predictor(X_mytrain, Y_mytrain, X_mytest,Y_mytest, LinearRegression)\n",
    "print select_predictor(X_mytrain, Y_mytrain, X_mytest,Y_mytest, RandomForestRegressor)\n",
    "print select_predictor(X_mytrain, Y_mytrain, X_mytest,Y_mytest, Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"sample1.csv\", LR_pred)\n",
    "write_to_file(\"sample2.csv\", RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
